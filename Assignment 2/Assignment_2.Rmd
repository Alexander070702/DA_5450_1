---
title: 'Data Analytics: Assignment 2 Group 6'
output: html_document
date: "29.03.2023"
---

### Load the caret package for data partitioning

```{r}
library("caret")
```

### Task 1: Load the data

Load the churn dataset from a [URL](https://statmath.wu.ac.at/~malsiner/datasets/churn.csv) and convert the churn variable to binary

```{r}
churndat <- read.csv(url("https://statmath.wu.ac.at/~malsiner/datasets/churn.csv"))
churndat$churn <- ifelse(churndat$churn == "Yes", 1, 0)
```

Convert the internationalplan and voicemailplan variables to binary

```{r}
churndat$internationalplan <- ifelse(churndat$internationalplan == "yes", 1, 0)
churndat$voicemailplan <- ifelse(churndat$voicemailplan == "yes", 1, 0)
```
```{r}
#structure of the data
str(churndat)

#Generate appropriate graphs for all variables differentiated into churn vs. no churn.
#accountlength
ggplot(churndat, aes(x = accountlength, fill = factor(churn))) + geom_histogram(bins = 20, position = "identity") + labs(title = "Account Length", x = "Account Length", y = "Frequency")
#internationalplan
ggplot(churndat, aes(x = internationalplan, fill = factor(churn))) + geom_bar(position = "identity") + labs(title = "International Plan", x = "International Plan", y = "Frequency")
#voicemailplan
ggplot(churndat, aes(x = voicemailplan, fill = factor(churn))) + geom_bar(position = "identity") + labs(title = "Voicemail Plan", x = "Voicemail Plan", y = "Frequency")
#numbervmailmessages
ggplot(churndat, aes(x = numbervmailmessages, fill = factor(churn))) + geom_histogram(bins = 20, position = "identity") + labs(title = "Number of Voicemail Messages", x = "Number of Voicemail Messages", y = "Frequency")
#totaldayminutes
ggplot(churndat, aes(x = totaldayminutes, fill = factor(churn))) + geom_histogram(bins = 20, position = "identity") + labs(title = "Total Day Minutes", x = "Total Day Minutes", y = "Frequency")
#totaleveminutes
ggplot(churndat, aes(x = totaleveminutes, fill = factor(churn))) + geom_histogram(bins = 20, position = "identity") + labs(title = "Total Eve Minutes", x = "Total Eve Minutes", y = "Frequency")
#totalnightminutes
ggplot(churndat, aes(x = totalnightminutes, fill = factor(churn))) + geom_histogram(bins = 20, position = "identity") + labs(title = "Total Night Minutes", x = "Total Night Minutes", y = "Frequency")
#totalintlcalls
ggplot(churndat, aes(x = totalintlcalls, fill = factor(churn))) + geom_histogram(bins = 20, position = "identity") + labs(title = "Total International Calls", x = "Total International Calls", y = "Frequency")
#totalintlcharge
ggplot(churndat, aes(x = totalintlcharge, fill = factor(churn))) + geom_histogram(bins = 20, position = "identity") + labs(title = "Total International Charge", x = "Total International Charge", y = "Frequency")
#numbercustomerservicecalls
ggplot(churndat, aes(x = numbercustomerservicecalls, fill = factor(churn))) + geom_histogram(bins = 20, position = "identity") + labs(title = "Number of Customer Service Calls", x = "Number of Customer Service Calls", y = "Frequency")

```

There seems to be a relationship with churn and international plan. If the user has no International plan the churn rate is way lower compared to users with an international plan
It is the opposite with the Voicemail plan, if the user has one the churn rate is lower.
Also with a rising number of customer service calls the churn rate seems to go up. The number of voicemail messages also seems to have some sort of influence, users with 0 seem to have a high churn rate.

For all the other variables it is difficult to tell and there seems to be no real correlation at first sight. 


### Task 2: Splitting the data to training set and test set

Split the data into training and testing sets, with 80% for training and 20% for testing

```{r}
set.seed(123) # for reproducibility
train_index <- createDataPartition(churndat$churn, p = 0.8, list = FALSE)
train <- churndat[train_index, ]
test <- churndat[-train_index, ]
```

### Task 3: Full logistic regression model

Fit a logistic regression model to the training data using all variables as predictors

```{r}
mlm <- glm(churn ~ ., data = train, family = binomial())
```

Print a summary of the logistic regression model

```{r}
summary(mlm)
```

Print a summary of the logistic regression model

```{r}
summary(mlm)
```

The significant variables in this model are: <b>internationalplan</b>, <b>voicemailplan</b>, <b>numbervmailmessages</b>, <b>totalintlcalls</b> and <b>numbercustomerservicecalls</b>.

### Task 4: Logistic model stepwise analysis

Perform stepwise variable selection on the logistic regression model using both forward and backward selection The 'trace' argument controls the amount of output produced during the stepwise procedure

```{r}
mlm_step <- step(mlm, direction = "both", trace = FALSE)
```

Print a summary of the stepwise logistic regression model

```{r}
summary(mlm_step)
```

Variables in the final model are : accountlength, internationalplan, voicemailplan, numbervmailmessages, totaldayminutes, totaleveminutes, totalnightminutes, totalintlcalls, totalintlcharge and numbercustomerservicecalls.

The coefficient of totaldayminutes suggests that there is a positive correlation between minutes talked and probability of leaving the company. Similarly, the coefficient of voicemailplan suggests a positive correlation between having a plan including a voicemail and the probability of leaving the company.

Calculate the predicted probabilities and predicted classes of the testing data using the stepwise logistic regression model

```{r}
test$prob_churn_step <- predict(mlm_step, newdata = test, type = "response")
test$class_churn_step <- ifelse(test$prob_churn_step > 0.5, 1, 0)
```

Calculate the accuracy, sensitivity, and specificity of the stepwise logistic regression model on the testing data

```{r}
accuracy_step <- sum(test$class_churn_step == test$churn) / nrow(test)
sensitivity_step <- sum(test$class_churn_step[test$churn == 1] == 1) / sum(test$churn == 1)
specificity_step <- sum(test$class_churn_step[test$churn == 0] == 0) / sum(test$churn == 0)
```

Print the accuracy, sensitivity, and specificity of the stepwise logistic regression model on the testing data

```{r}
cat("Accuracy: ", round(accuracy_step, 4), "\n")
cat("Sensitivity: ", round(sensitivity_step, 4), "\n")
cat("Specificity: ", round(specificity_step, 4), "\n")
```
### Task 5: k-NN modell using 5 fold cross-validation

```{r}
fitControl <- trainControl(method = "cv", number = 5)

logFit <- train(as.factor(churn) ~ scale(accountlength) + internationalplan + voicemailplan + scale(totalintlcharge) + scale(numbervmailmessages) + scale(totaldayminutes) + scale(totaldaycharge) + scale(totalevecalls) + scale(totaleveminutes) + scale(totalnightminutes) + scale(totalintlminutes) + 
scale(totalintlcalls) + scale(numbercustomerservicecalls) + scale(totalnightcharge) + scale(totaldaycalls) + scale(totalevecharge) + scale(totalnightcalls),data = train, method= "knn", tuneGrid = data.frame(k = 1:10), trControl = fitControl)

logFit

```

### Task 6: Naive Bayes model estemated on training sample

```{r}
library(e1071)
fit_nb = naiveBayes(churn ~ internationalplan + voicemailplan + numbercustomerservicecalls + totalintlcalls + numbervmailmessages, data = train)

fit_nb
```
### Task 7: Comparing the different methods

```{r}
# Predict churn using the k-NN model
library(class)
knn_pred <- knn(train[,c("internationalplan", "voicemailplan", "numbercustomerservicecalls", "totalintlcalls", "numbervmailmessages")], test[,c("internationalplan", "voicemailplan", "numbercustomerservicecalls", "totalintlcalls", "numbervmailmessages")], train$churn, k=5)
knn_cm <- table(test$churn, knn_pred)
knn_accuracy <- sum(diag(knn_cm))/sum(knn_cm)

# Predict churn using the Naive Bayes model
nb_pred <- predict(fit_nb, newdata = test)
nb_cm <- table(test$churn, nb_pred)
nb_accuracy <- sum(diag(nb_cm))/sum(nb_cm)

# Calculate accuracy, sensitivity, and specificity of the stepwise logistic regression model
test$prob_churn_step <- predict(mlm_step, newdata = test, type = "response")
test$class_churn_step <- ifelse(test$prob_churn_step > 0.5, 1, 0)
accuracy_step <- sum(test$class_churn_step == test$churn) / nrow(test)
sensitivity_step <- sum(test$class_churn_step[test$churn == 1] == 1) / sum(test$churn == 1)
specificity_step <- sum(test$class_churn_step[test$churn == 0] == 0) / sum(test$churn == 0)

# Print the evaluation metrics
cat("Stepwise logistic regression model: Accuracy=", round(accuracy_step, 4), " Sensitivity=", round(sensitivity_step, 4), " Specificity=", round(specificity_step, 4), "\n")
cat("k-NN model: Accuracy=", round(knn_accuracy, 4), " Sensitivity=", round(knn_cm[2,2]/sum(knn_cm[2,]), 4), " Specificity=", round(knn_cm[1,1]/sum(knn_cm[1,]), 4), "\n")
cat("Naive Bayes model: Accuracy=", round(nb_accuracy, 4), " Sensitivity=", round(nb_cm[2,2]/sum(nb_cm[2,]), 4), " Specificity=", round(nb_cm[1,1]/sum(nb_cm[1,]), 4), "\n")
```
